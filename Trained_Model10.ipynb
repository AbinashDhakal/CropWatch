{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf0a1c9-600e-49fb-a16d-290f67f944c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No model config found in the file at C:\\Users\\abudh\\Desktop\\CropWatch\\best_trained_weights.weights.h5.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 176\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Main function\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m model \u001b[38;5;241m=\u001b[39m load_trained_model(model_path)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Load images for classification\u001b[39;00m\n\u001b[0;32m    179\u001b[0m images \u001b[38;5;241m=\u001b[39m load_and_prepare_images(test_folder)\n",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m, in \u001b[0;36mload_trained_model\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_trained_model\u001b[39m(model_path):\n\u001b[1;32m---> 21\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_model(model_path)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Print model summary to check output shape\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:189\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    183\u001b[0m         filepath,\n\u001b[0;32m    184\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    186\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    190\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:125\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    123\u001b[0m model_config \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model config found in the file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    129\u001b[0m     model_config \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No model config found in the file at C:\\Users\\abudh\\Desktop\\CropWatch\\best_trained_weights.weights.h5."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Configuration\n",
    "test_folder = r'C:\\Users\\abudh\\Desktop\\CropWatch\\Test2'\n",
    "filtered_image_folder = r'C:\\Users\\abudh\\Desktop\\CropWatch\\Filtered_Image'\n",
    "model_path = r'C:\\Users\\abudh\\Desktop\\CropWatch\\best_trained_weights.weights.h5'\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "n = 3  # Number of rows and columns to splice the image into\n",
    "threshold_percentage = 30  # Threshold for cloud coverage\n",
    "\n",
    "vegetation_classes = [\"AnnualCrop\", \"Forest\", \"HerbaceousVegetation\", \"Pasture\", \"PermanentCrop\"]\n",
    "\n",
    "# Load trained model\n",
    "def load_trained_model(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    \n",
    "    # Print model summary to check output shape\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Preprocess image for prediction\n",
    "def preprocess_image(image):\n",
    "    img = image.resize((img_width, img_height))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Splice image into parts\n",
    "def splice_image(file_path, n):\n",
    "    img = Image.open(file_path)\n",
    "    width, height = img.size\n",
    "    cropped_images = []\n",
    "    tile_width = width // n\n",
    "    tile_height = height // n\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            left = j * tile_width\n",
    "            upper = i * tile_height\n",
    "            right = left + tile_width\n",
    "            lower = upper + tile_height\n",
    "            cropped_img = img.crop((left, upper, right, lower))\n",
    "            cropped_images.append((cropped_img, i * n + j + 1))\n",
    "    return cropped_images\n",
    "\n",
    "# Mask clouds and interpolate\n",
    "def mask_clouds(image, t1=0.1, t2=0.1, kernel_size=10, inpaint_radius=5):\n",
    "    # Convert PIL image to NumPy array\n",
    "    image = np.array(image)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image conversion failed, image is None\")\n",
    "\n",
    "    R = image[:, :, 2]\n",
    "    G = image[:, :, 1]\n",
    "    B = image[:, :, 0]\n",
    "\n",
    "    rg = R / (G + 1e-6)\n",
    "    gb = G / (B + 1e-6)\n",
    "\n",
    "    cloud_mask1 = np.logical_and(np.abs(rg - 1) < t1, np.abs(gb - 1) < t2).astype(np.uint8)\n",
    "    cloud_mask = cv2.dilate(cloud_mask1, kernel=np.ones((kernel_size, kernel_size), dtype=np.uint8), iterations=1)\n",
    "\n",
    "    R_inpaint = cv2.inpaint(R, cloud_mask, inpaint_radius, cv2.INPAINT_TELEA)\n",
    "    G_inpaint = cv2.inpaint(G, cloud_mask, inpaint_radius, cv2.INPAINT_TELEA)\n",
    "    B_inpaint = cv2.inpaint(B, cloud_mask, inpaint_radius, cv2.INPAINT_TELEA)\n",
    "\n",
    "    inpainted_image = np.stack([B_inpaint, G_inpaint, R_inpaint], axis=2)\n",
    "\n",
    "    cloud_cover = np.sum(cloud_mask) / cloud_mask.size * 100\n",
    "    return cloud_cover\n",
    "\n",
    "def analyze_image_parts(image_path, n, threshold_percentage):\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    output_folder = filtered_image_folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    cropped_images = splice_image(image_path, n)\n",
    "    \n",
    "    for cropped_img, idx in cropped_images:\n",
    "        cloud_cover = mask_clouds(cropped_img)  # Directly use cropped_img\n",
    "        \n",
    "        status = \"Accepted\" if cloud_cover < threshold_percentage else \"Rejected\"\n",
    "        print(f\"Part {idx} Cloud Coverage: {cloud_cover:.2f}% - {status}\")\n",
    "        \n",
    "        if cloud_cover < threshold_percentage:\n",
    "            # Save the image in the appropriate vegetation class folder\n",
    "            img_array = preprocess_image(cropped_img)\n",
    "            img_array_exp = np.expand_dims(img_array, axis=0)\n",
    "            prediction = model.predict(img_array_exp)\n",
    "            \n",
    "            # Debug prints\n",
    "            print(f\"Prediction shape: {prediction.shape}\")\n",
    "            print(f\"Prediction values: {prediction}\")\n",
    "            \n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "            print(f\"Predicted class index: {predicted_class}\")\n",
    "            \n",
    "            if predicted_class < len(vegetation_classes):\n",
    "                predicted_label = vegetation_classes[predicted_class]\n",
    "                \n",
    "                if predicted_label in vegetation_classes:\n",
    "                    class_folder = os.path.join(filtered_image_folder, predicted_label)\n",
    "                    os.makedirs(class_folder, exist_ok=True)\n",
    "                    output_name = f\"{base_name}_Q{idx}.png\"\n",
    "                    output_path = os.path.join(class_folder, output_name)\n",
    "                    cropped_img.save(output_path)\n",
    "                    print(f\"Spliced image {output_name} saved to {output_path}\")\n",
    "            else:\n",
    "                print(f\"Predicted class index {predicted_class} is out of range.\")\n",
    "\n",
    "# Classify and save images\n",
    "def classify_and_save_images(images, model, vegetation_classes, filtered_image_folder, n):\n",
    "    if not os.path.exists(filtered_image_folder):\n",
    "        os.makedirs(filtered_image_folder)\n",
    "\n",
    "    for veg_class in vegetation_classes:\n",
    "        class_folder = os.path.join(filtered_image_folder, veg_class)\n",
    "        if not os.path.exists(class_folder):\n",
    "            os.makedirs(class_folder)\n",
    "\n",
    "    for file_path, img_array in images:\n",
    "        try:\n",
    "            img_array_exp = np.expand_dims(img_array, axis=0)\n",
    "            prediction = model.predict(img_array_exp)\n",
    "            \n",
    "            # Debug prints\n",
    "            print(f\"Prediction shape: {prediction.shape}\")\n",
    "            print(f\"Prediction values: {prediction}\")\n",
    "            \n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "            print(f\"Predicted class index: {predicted_class}\")\n",
    "            \n",
    "            if predicted_class < len(vegetation_classes):\n",
    "                predicted_label = vegetation_classes[predicted_class]\n",
    "\n",
    "                if predicted_label in vegetation_classes:\n",
    "                    # Splice the image if it's a vegetation class\n",
    "                    cropped_images = splice_image(file_path, n)\n",
    "                    \n",
    "                    for cropped_img, idx in cropped_images:\n",
    "                        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "                        new_filename = f\"{base_name}_part{idx}.jpg\"\n",
    "                        save_path = os.path.join(filtered_image_folder, predicted_label, new_filename)\n",
    "\n",
    "                        cropped_img.save(save_path)\n",
    "                        print(f\"Spliced image {file_path} classified as {predicted_label} and saved to {save_path}\")\n",
    "            else:\n",
    "                print(f\"Image {file_path} classified as {predicted_label} but not a vegetation class.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {file_path}: {e}\")\n",
    "\n",
    "# Load and prepare images for prediction\n",
    "def load_and_prepare_images(folder):\n",
    "    image_files = glob.glob(os.path.join(folder, '*.*'))\n",
    "    images = []\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            with Image.open(file) as img:\n",
    "                img_array = preprocess_image(img)\n",
    "                images.append((file, img_array))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {file}: {e}\")\n",
    "    return images\n",
    "\n",
    "print(\"Hello1\")\n",
    "\n",
    "# Main function\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "# Load images for classification\n",
    "images = load_and_prepare_images(test_folder)\n",
    "print(\"Hello2\")\n",
    "# Classify and save images\n",
    "classify_and_save_images(images, model, vegetation_classes, filtered_image_folder, n)\n",
    "print(\"Hello3\")\n",
    "\n",
    "# Analyze image parts\n",
    "image_files = glob.glob(os.path.join(test_folder, '*.*'))\n",
    "for image_file in image_files:\n",
    "    analyze_image_parts(image_file, n, threshold_percentage)\n",
    "\n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084425e-a4c6-4af3-9db3-b6494e2cb728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
