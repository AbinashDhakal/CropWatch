{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6a7c31-7227-4cfb-a618-e4c84056c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08064292-54ad-4f90-894a-11fbfe41db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27000 files belonging to 10 classes.\n",
      "Found 21600 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n",
      "Class weights:\n",
      "Class 'AnnualCrop': 0.9000\n",
      "Class 'Forest': 0.9000\n",
      "Class 'HerbaceousVegetation': 0.9000\n",
      "Class 'Highway': 1.0800\n",
      "Class 'Industrial': 1.0800\n",
      "Class 'Pasture': 1.3500\n",
      "Class 'PermanentCrop': 1.0800\n",
      "Class 'Residential': 0.9000\n",
      "Class 'River': 1.0800\n",
      "Class 'SeaLake': 0.9000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abudh\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  4/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:08\u001b[0m 1s/step - accuracy: 0.9558 - loss: 0.1093  \n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m  9/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:31\u001b[0m 1s/step - accuracy: 0.9401 - loss: 0.1537\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 14/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:33\u001b[0m 1s/step - accuracy: 0.9352 - loss: 0.1692\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 19/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:30\u001b[0m 1s/step - accuracy: 0.9341 - loss: 0.1734\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 24/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:26\u001b[0m 1s/step - accuracy: 0.9335 - loss: 0.1766\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 29/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:19\u001b[0m 1s/step - accuracy: 0.9338 - loss: 0.1780\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 34/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:14\u001b[0m 1s/step - accuracy: 0.9340 - loss: 0.1794\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 39/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:07\u001b[0m 1s/step - accuracy: 0.9342 - loss: 0.1807\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 44/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:01\u001b[0m 1s/step - accuracy: 0.9343 - loss: 0.1818\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 49/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:55\u001b[0m 1s/step - accuracy: 0.9344 - loss: 0.1824\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 54/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:48\u001b[0m 1s/step - accuracy: 0.9344 - loss: 0.1833\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 59/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:41\u001b[0m 1s/step - accuracy: 0.9343 - loss: 0.1843\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 64/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:33\u001b[0m 1s/step - accuracy: 0.9341 - loss: 0.1855\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 69/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:30\u001b[0m 1s/step - accuracy: 0.9341 - loss: 0.1865\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 74/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:24\u001b[0m 1s/step - accuracy: 0.9339 - loss: 0.1878\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 79/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:21\u001b[0m 1s/step - accuracy: 0.9337 - loss: 0.1889\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 84/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:16\u001b[0m 1s/step - accuracy: 0.9336 - loss: 0.1897\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 89/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:10\u001b[0m 1s/step - accuracy: 0.9336 - loss: 0.1904\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 94/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:05\u001b[0m 1s/step - accuracy: 0.9336 - loss: 0.1908\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m 99/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:58\u001b[0m 1s/step - accuracy: 0.9335 - loss: 0.1912\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m104/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:51\u001b[0m 1s/step - accuracy: 0.9334 - loss: 0.1916\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m109/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:44\u001b[0m 1s/step - accuracy: 0.9333 - loss: 0.1921\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m114/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:38\u001b[0m 1s/step - accuracy: 0.9332 - loss: 0.1926\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m119/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:31\u001b[0m 1s/step - accuracy: 0.9331 - loss: 0.1930\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m124/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:24\u001b[0m 1s/step - accuracy: 0.9330 - loss: 0.1935\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m129/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:17\u001b[0m 1s/step - accuracy: 0.9329 - loss: 0.1940\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m134/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:10\u001b[0m 1s/step - accuracy: 0.9328 - loss: 0.1944\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m139/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:03\u001b[0m 1s/step - accuracy: 0.9327 - loss: 0.1947\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m144/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:55\u001b[0m 1s/step - accuracy: 0.9326 - loss: 0.1950\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m149/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:48\u001b[0m 1s/step - accuracy: 0.9325 - loss: 0.1953\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m154/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:41\u001b[0m 1s/step - accuracy: 0.9324 - loss: 0.1955\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m159/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:34\u001b[0m 1s/step - accuracy: 0.9324 - loss: 0.1958\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m164/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:27\u001b[0m 1s/step - accuracy: 0.9323 - loss: 0.1959\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m169/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:20\u001b[0m 1s/step - accuracy: 0.9323 - loss: 0.1961\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m174/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m31:26\u001b[0m 7s/step - accuracy: 0.9322 - loss: 0.1962\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m179/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30:09\u001b[0m 7s/step - accuracy: 0.9321 - loss: 0.1963\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m184/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m28:55\u001b[0m 7s/step - accuracy: 0.9321 - loss: 0.1965\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m189/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m27:45\u001b[0m 7s/step - accuracy: 0.9320 - loss: 0.1966\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m194/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26:38\u001b[0m 7s/step - accuracy: 0.9320 - loss: 0.1966\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m199/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m25:34\u001b[0m 7s/step - accuracy: 0.9319 - loss: 0.1967\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m204/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24:33\u001b[0m 6s/step - accuracy: 0.9319 - loss: 0.1967\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m209/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23:34\u001b[0m 6s/step - accuracy: 0.9319 - loss: 0.1967\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m214/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22:37\u001b[0m 6s/step - accuracy: 0.9319 - loss: 0.1967\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m219/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21:43\u001b[0m 6s/step - accuracy: 0.9319 - loss: 0.1967\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m224/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20:51\u001b[0m 6s/step - accuracy: 0.9319 - loss: 0.1968\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m229/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20:00\u001b[0m 6s/step - accuracy: 0.9318 - loss: 0.1969\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m234/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19:12\u001b[0m 6s/step - accuracy: 0.9318 - loss: 0.1969\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m239/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18:26\u001b[0m 6s/step - accuracy: 0.9318 - loss: 0.1970\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m244/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17:40\u001b[0m 6s/step - accuracy: 0.9317 - loss: 0.1971\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m249/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16:57\u001b[0m 6s/step - accuracy: 0.9317 - loss: 0.1972\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m254/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16:15\u001b[0m 5s/step - accuracy: 0.9317 - loss: 0.1973\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m259/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m15:34\u001b[0m 5s/step - accuracy: 0.9316 - loss: 0.1974\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m264/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14:54\u001b[0m 5s/step - accuracy: 0.9316 - loss: 0.1975\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m269/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14:16\u001b[0m 5s/step - accuracy: 0.9316 - loss: 0.1976\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m274/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13:39\u001b[0m 5s/step - accuracy: 0.9316 - loss: 0.1977\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m279/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13:03\u001b[0m 5s/step - accuracy: 0.9315 - loss: 0.1978\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m284/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12:28\u001b[0m 5s/step - accuracy: 0.9315 - loss: 0.1978\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m289/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11:53\u001b[0m 5s/step - accuracy: 0.9315 - loss: 0.1979\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m294/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11:20\u001b[0m 5s/step - accuracy: 0.9315 - loss: 0.1979\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m299/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:17:31\u001b[0m 35s/step - accuracy: 0.9315 - loss: 0.1979\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m304/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:13:26\u001b[0m 34s/step - accuracy: 0.9315 - loss: 0.1980\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m309/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:09:28\u001b[0m 34s/step - accuracy: 0.9314 - loss: 0.1980\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m314/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:05:37\u001b[0m 33s/step - accuracy: 0.9314 - loss: 0.1981\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m319/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:01:54\u001b[0m 33s/step - accuracy: 0.9314 - loss: 0.1981\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m324/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m58:17\u001b[0m 32s/step - accuracy: 0.9314 - loss: 0.1982\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m329/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m54:47\u001b[0m 32s/step - accuracy: 0.9314 - loss: 0.1982\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m334/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m51:22\u001b[0m 31s/step - accuracy: 0.9313 - loss: 0.1983\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m339/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m48:04\u001b[0m 31s/step - accuracy: 0.9313 - loss: 0.1983\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m344/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m44:51\u001b[0m 31s/step - accuracy: 0.9313 - loss: 0.1983\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m349/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41:43\u001b[0m 30s/step - accuracy: 0.9313 - loss: 0.1984\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m354/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m38:41\u001b[0m 30s/step - accuracy: 0.9313 - loss: 0.1984\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m359/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m35:43\u001b[0m 29s/step - accuracy: 0.9313 - loss: 0.1984\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m364/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32:50\u001b[0m 29s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m369/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m30:02\u001b[0m 29s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m374/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27:17\u001b[0m 28s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m379/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24:38\u001b[0m 28s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m384/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22:02\u001b[0m 28s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m389/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m19:30\u001b[0m 27s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m394/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17:01\u001b[0m 27s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m399/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14:36\u001b[0m 27s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m404/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12:15\u001b[0m 26s/step - accuracy: 0.9312 - loss: 0.1985\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m409/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9:56\u001b[0m 26s/step - accuracy: 0.9312 - loss: 0.1985 \n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m414/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7:41\u001b[0m 26s/step - accuracy: 0.9312 - loss: 0.1984\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m419/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5:29\u001b[0m 25s/step - accuracy: 0.9312 - loss: 0.1984\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m424/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:20\u001b[0m 25s/step - accuracy: 0.9312 - loss: 0.1984\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m429/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:14\u001b[0m 25s/step - accuracy: 0.9312 - loss: 0.1984\n",
      "Epoch 1: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch01.weights.h5\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.9312 - loss: 0.1984 \n",
      "Epoch 1: val_loss improved from inf to 0.36257, saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\best_trained_weights.weights.h5\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10753s\u001b[0m 25s/step - accuracy: 0.9312 - loss: 0.1984 - val_accuracy: 0.8752 - val_loss: 0.3626 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m  2/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:49\u001b[0m 1s/step - accuracy: 0.9400 - loss: 0.1813 \n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m  7/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:33\u001b[0m 1s/step - accuracy: 0.9456 - loss: 0.1859\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 12/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:38\u001b[0m 1s/step - accuracy: 0.9456 - loss: 0.1772\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 17/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:37\u001b[0m 1s/step - accuracy: 0.9457 - loss: 0.1750\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 22/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:33\u001b[0m 1s/step - accuracy: 0.9461 - loss: 0.1743\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 27/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:26\u001b[0m 1s/step - accuracy: 0.9453 - loss: 0.1757\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 32/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:22\u001b[0m 1s/step - accuracy: 0.9443 - loss: 0.1769\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 37/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:15\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.1780\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 42/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:07\u001b[0m 1s/step - accuracy: 0.9427 - loss: 0.1783\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 47/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:00\u001b[0m 1s/step - accuracy: 0.9421 - loss: 0.1793\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 52/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:52\u001b[0m 1s/step - accuracy: 0.9412 - loss: 0.1804\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 57/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:46\u001b[0m 1s/step - accuracy: 0.9405 - loss: 0.1813\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 62/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:39\u001b[0m 1s/step - accuracy: 0.9400 - loss: 0.1818\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 67/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:33\u001b[0m 1s/step - accuracy: 0.9395 - loss: 0.1825\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 72/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:25\u001b[0m 1s/step - accuracy: 0.9390 - loss: 0.1830\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 77/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:18\u001b[0m 1s/step - accuracy: 0.9386 - loss: 0.1833\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 82/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:11\u001b[0m 1s/step - accuracy: 0.9383 - loss: 0.1835\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 87/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:05\u001b[0m 1s/step - accuracy: 0.9380 - loss: 0.1837\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 92/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:58\u001b[0m 1s/step - accuracy: 0.9378 - loss: 0.1839\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m 97/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:52\u001b[0m 1s/step - accuracy: 0.9376 - loss: 0.1840\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m102/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:45\u001b[0m 1s/step - accuracy: 0.9374 - loss: 0.1841\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m107/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:40\u001b[0m 1s/step - accuracy: 0.9373 - loss: 0.1841\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m112/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:33\u001b[0m 1s/step - accuracy: 0.9371 - loss: 0.1842\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m117/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:27\u001b[0m 1s/step - accuracy: 0.9370 - loss: 0.1843\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m122/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:20\u001b[0m 1s/step - accuracy: 0.9369 - loss: 0.1844\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m127/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:13\u001b[0m 1s/step - accuracy: 0.9368 - loss: 0.1844\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m132/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:06\u001b[0m 1s/step - accuracy: 0.9367 - loss: 0.1846\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m137/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:59\u001b[0m 1s/step - accuracy: 0.9366 - loss: 0.1847\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m142/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:53\u001b[0m 1s/step - accuracy: 0.9365 - loss: 0.1848\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m147/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:46\u001b[0m 1s/step - accuracy: 0.9364 - loss: 0.1848\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m152/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:39\u001b[0m 1s/step - accuracy: 0.9364 - loss: 0.1849\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m157/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:32\u001b[0m 1s/step - accuracy: 0.9363 - loss: 0.1849\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m162/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:24\u001b[0m 1s/step - accuracy: 0.9363 - loss: 0.1850\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m167/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:16:46\u001b[0m 45s/step - accuracy: 0.9362 - loss: 0.1851\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m172/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:07:36\u001b[0m 43s/step - accuracy: 0.9362 - loss: 0.1853\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m177/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:58:55\u001b[0m 42s/step - accuracy: 0.9361 - loss: 0.1855\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m182/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:50:43\u001b[0m 41s/step - accuracy: 0.9360 - loss: 0.1857\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m187/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:42:57\u001b[0m 40s/step - accuracy: 0.9360 - loss: 0.1859\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m192/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:35:35\u001b[0m 39s/step - accuracy: 0.9359 - loss: 0.1861\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m197/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:28:36\u001b[0m 38s/step - accuracy: 0.9358 - loss: 0.1863\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m202/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:21:57\u001b[0m 37s/step - accuracy: 0.9358 - loss: 0.1865\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m207/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:15:38\u001b[0m 36s/step - accuracy: 0.9357 - loss: 0.1868\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m212/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:04:24\u001b[0m 50s/step - accuracy: 0.9356 - loss: 0.1871\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m217/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:56:10\u001b[0m 49s/step - accuracy: 0.9355 - loss: 0.1873\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m222/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:48:17\u001b[0m 48s/step - accuracy: 0.9354 - loss: 0.1876\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m227/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:40:45\u001b[0m 47s/step - accuracy: 0.9353 - loss: 0.1879\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m232/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:33:32\u001b[0m 46s/step - accuracy: 0.9352 - loss: 0.1882\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m237/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:26:37\u001b[0m 45s/step - accuracy: 0.9351 - loss: 0.1886\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m242/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:19:59\u001b[0m 44s/step - accuracy: 0.9350 - loss: 0.1890\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m247/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:13:37\u001b[0m 43s/step - accuracy: 0.9348 - loss: 0.1894\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m252/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:07:30\u001b[0m 43s/step - accuracy: 0.9347 - loss: 0.1897\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m257/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:01:37\u001b[0m 42s/step - accuracy: 0.9346 - loss: 0.1901\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m262/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:55:58\u001b[0m 41s/step - accuracy: 0.9345 - loss: 0.1906\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m267/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:50:30\u001b[0m 40s/step - accuracy: 0.9344 - loss: 0.1910\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m272/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:45:15\u001b[0m 39s/step - accuracy: 0.9343 - loss: 0.1913\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m277/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:40:11\u001b[0m 39s/step - accuracy: 0.9342 - loss: 0.1917\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m282/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:35:17\u001b[0m 38s/step - accuracy: 0.9341 - loss: 0.1920\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m287/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:30:34\u001b[0m 37s/step - accuracy: 0.9340 - loss: 0.1924\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m292/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:26:00\u001b[0m 37s/step - accuracy: 0.9339 - loss: 0.1927\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m297/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:21:34\u001b[0m 36s/step - accuracy: 0.9338 - loss: 0.1930\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m302/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:17:18\u001b[0m 36s/step - accuracy: 0.9337 - loss: 0.1933\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m307/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:13:09\u001b[0m 35s/step - accuracy: 0.9337 - loss: 0.1936\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m312/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:09:09\u001b[0m 35s/step - accuracy: 0.9336 - loss: 0.1939\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m317/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:05:16\u001b[0m 34s/step - accuracy: 0.9335 - loss: 0.1942\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m322/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:01:29\u001b[0m 34s/step - accuracy: 0.9334 - loss: 0.1944\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m327/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m57:50\u001b[0m 33s/step - accuracy: 0.9334 - loss: 0.1947\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m332/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m54:17\u001b[0m 33s/step - accuracy: 0.9333 - loss: 0.1949\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m337/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m50:51\u001b[0m 32s/step - accuracy: 0.9332 - loss: 0.1952\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m342/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47:31\u001b[0m 32s/step - accuracy: 0.9332 - loss: 0.1954\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m347/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m44:16\u001b[0m 31s/step - accuracy: 0.9331 - loss: 0.1957\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m352/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41:06\u001b[0m 31s/step - accuracy: 0.9330 - loss: 0.1959\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m357/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m38:01\u001b[0m 30s/step - accuracy: 0.9330 - loss: 0.1961\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m362/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m35:01\u001b[0m 30s/step - accuracy: 0.9329 - loss: 0.1963\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m367/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32:06\u001b[0m 30s/step - accuracy: 0.9329 - loss: 0.1965\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m372/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m29:16\u001b[0m 29s/step - accuracy: 0.9328 - loss: 0.1969\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m377/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26:29\u001b[0m 29s/step - accuracy: 0.9327 - loss: 0.1973\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m382/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m23:47\u001b[0m 29s/step - accuracy: 0.9326 - loss: 0.1978\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m387/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m21:09\u001b[0m 28s/step - accuracy: 0.9324 - loss: 0.1984\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m392/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18:34\u001b[0m 28s/step - accuracy: 0.9323 - loss: 0.1989\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m397/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16:03\u001b[0m 28s/step - accuracy: 0.9321 - loss: 0.1995\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m402/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13:36\u001b[0m 27s/step - accuracy: 0.9320 - loss: 0.2001\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m407/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11:12\u001b[0m 27s/step - accuracy: 0.9318 - loss: 0.2007\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m412/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8:51\u001b[0m 27s/step - accuracy: 0.9316 - loss: 0.2013\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m417/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8:25\u001b[0m 34s/step - accuracy: 0.9315 - loss: 0.2019\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m422/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6:13\u001b[0m 37s/step - accuracy: 0.9313 - loss: 0.2025\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m427/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3:04\u001b[0m 37s/step - accuracy: 0.9311 - loss: 0.2032\n",
      "Epoch 2: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch02.weights.h5\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36s/step - accuracy: 0.9310 - loss: 0.2038 \n",
      "Epoch 2: val_loss did not improve from 0.36257\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15786s\u001b[0m 37s/step - accuracy: 0.9309 - loss: 0.2039 - val_accuracy: 0.6015 - val_loss: 1.2651 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m  5/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:30\u001b[0m 1s/step - accuracy: 0.8751 - loss: 0.3440\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 10/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:54\u001b[0m 1s/step - accuracy: 0.8805 - loss: 0.3306\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 15/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:12\u001b[0m 1s/step - accuracy: 0.8831 - loss: 0.3244\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 20/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:24\u001b[0m 1s/step - accuracy: 0.8859 - loss: 0.3158\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 25/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:46\u001b[0m 1s/step - accuracy: 0.8886 - loss: 0.3081\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 30/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:04\u001b[0m 2s/step - accuracy: 0.8907 - loss: 0.3016\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 35/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:08\u001b[0m 2s/step - accuracy: 0.8918 - loss: 0.2977\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 40/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:04\u001b[0m 2s/step - accuracy: 0.8928 - loss: 0.2956\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 45/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:05\u001b[0m 2s/step - accuracy: 0.8940 - loss: 0.2926\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 50/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:03\u001b[0m 2s/step - accuracy: 0.8952 - loss: 0.2898\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 55/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:00\u001b[0m 2s/step - accuracy: 0.8965 - loss: 0.2874\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 60/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:59\u001b[0m 2s/step - accuracy: 0.8977 - loss: 0.2854 \n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 65/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:55\u001b[0m 2s/step - accuracy: 0.8989 - loss: 0.2836\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 70/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:50\u001b[0m 2s/step - accuracy: 0.8999 - loss: 0.2820\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 75/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:46\u001b[0m 2s/step - accuracy: 0.9008 - loss: 0.2808\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 80/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:41\u001b[0m 2s/step - accuracy: 0.9016 - loss: 0.2794\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 85/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:35\u001b[0m 2s/step - accuracy: 0.9024 - loss: 0.2782\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 90/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:30\u001b[0m 2s/step - accuracy: 0.9032 - loss: 0.2769\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m 95/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:25\u001b[0m 2s/step - accuracy: 0.9039 - loss: 0.2758\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m100/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:21\u001b[0m 2s/step - accuracy: 0.9045 - loss: 0.2747\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m105/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:14\u001b[0m 2s/step - accuracy: 0.9051 - loss: 0.2739\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m110/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:07\u001b[0m 2s/step - accuracy: 0.9056 - loss: 0.2730\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m115/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:58\u001b[0m 2s/step - accuracy: 0.9061 - loss: 0.2723\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m120/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:50\u001b[0m 2s/step - accuracy: 0.9065 - loss: 0.2715\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m125/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:43\u001b[0m 2s/step - accuracy: 0.9070 - loss: 0.2707\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m130/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:35\u001b[0m 2s/step - accuracy: 0.9074 - loss: 0.2698\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m135/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:28\u001b[0m 2s/step - accuracy: 0.9078 - loss: 0.2689\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m140/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:20\u001b[0m 2s/step - accuracy: 0.9083 - loss: 0.2680\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m145/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:12\u001b[0m 2s/step - accuracy: 0.9087 - loss: 0.2671\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m150/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:04\u001b[0m 2s/step - accuracy: 0.9091 - loss: 0.2662\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m155/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:56\u001b[0m 2s/step - accuracy: 0.9094 - loss: 0.2655\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m160/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:48\u001b[0m 2s/step - accuracy: 0.9098 - loss: 0.2647\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m165/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:40\u001b[0m 2s/step - accuracy: 0.9101 - loss: 0.2639\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m170/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:32\u001b[0m 2s/step - accuracy: 0.9105 - loss: 0.2631\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m175/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:25\u001b[0m 2s/step - accuracy: 0.9108 - loss: 0.2624\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m180/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:17\u001b[0m 2s/step - accuracy: 0.9111 - loss: 0.2617\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m185/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:09\u001b[0m 2s/step - accuracy: 0.9114 - loss: 0.2610\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m190/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:00\u001b[0m 2s/step - accuracy: 0.9117 - loss: 0.2603\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m195/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:53\u001b[0m 2s/step - accuracy: 0.9119 - loss: 0.2598\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m200/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:45\u001b[0m 2s/step - accuracy: 0.9121 - loss: 0.2592\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m205/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:37\u001b[0m 2s/step - accuracy: 0.9123 - loss: 0.2587\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m210/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:28\u001b[0m 2s/step - accuracy: 0.9125 - loss: 0.2582\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m215/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:20\u001b[0m 2s/step - accuracy: 0.9127 - loss: 0.2577\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m220/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6:12\u001b[0m 2s/step - accuracy: 0.9129 - loss: 0.2572\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m225/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6:04\u001b[0m 2s/step - accuracy: 0.9131 - loss: 0.2568\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m230/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:56\u001b[0m 2s/step - accuracy: 0.9133 - loss: 0.2563\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m235/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:47\u001b[0m 2s/step - accuracy: 0.9135 - loss: 0.2558\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m240/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:39\u001b[0m 2s/step - accuracy: 0.9137 - loss: 0.2553\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m245/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:30\u001b[0m 2s/step - accuracy: 0.9139 - loss: 0.2548\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m250/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:21\u001b[0m 2s/step - accuracy: 0.9140 - loss: 0.2544\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m255/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:13\u001b[0m 2s/step - accuracy: 0.9142 - loss: 0.2539\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m260/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5:05\u001b[0m 2s/step - accuracy: 0.9144 - loss: 0.2534\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m265/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:57\u001b[0m 2s/step - accuracy: 0.9146 - loss: 0.2530\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m270/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:48\u001b[0m 2s/step - accuracy: 0.9147 - loss: 0.2526\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m275/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:39\u001b[0m 2s/step - accuracy: 0.9149 - loss: 0.2522\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m280/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:30\u001b[0m 2s/step - accuracy: 0.9150 - loss: 0.2518\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m285/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 2s/step - accuracy: 0.9152 - loss: 0.2515\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m290/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 2s/step - accuracy: 0.9153 - loss: 0.2511\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m295/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4:04\u001b[0m 2s/step - accuracy: 0.9155 - loss: 0.2508\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m300/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:55\u001b[0m 2s/step - accuracy: 0.9156 - loss: 0.2505\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m305/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:47\u001b[0m 2s/step - accuracy: 0.9157 - loss: 0.2501\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m310/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:38\u001b[0m 2s/step - accuracy: 0.9158 - loss: 0.2498\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m315/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:29\u001b[0m 2s/step - accuracy: 0.9159 - loss: 0.2495\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m320/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 2s/step - accuracy: 0.9160 - loss: 0.2492\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m325/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 2s/step - accuracy: 0.9161 - loss: 0.2489\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m330/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 2s/step - accuracy: 0.9162 - loss: 0.2486\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m335/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 2s/step - accuracy: 0.9163 - loss: 0.2484\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m340/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 2s/step - accuracy: 0.9164 - loss: 0.2481\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m345/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 2s/step - accuracy: 0.9165 - loss: 0.2478\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m350/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:28\u001b[0m 2s/step - accuracy: 0.9166 - loss: 0.2475\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m355/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:19\u001b[0m 2s/step - accuracy: 0.9167 - loss: 0.2473\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m360/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:10\u001b[0m 2s/step - accuracy: 0.9168 - loss: 0.2470\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m365/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:01\u001b[0m 2s/step - accuracy: 0.9169 - loss: 0.2468\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m370/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:52\u001b[0m 2s/step - accuracy: 0.9170 - loss: 0.2465\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m375/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:43\u001b[0m 2s/step - accuracy: 0.9171 - loss: 0.2463\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m380/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:34\u001b[0m 2s/step - accuracy: 0.9171 - loss: 0.2460\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m385/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:25\u001b[0m 2s/step - accuracy: 0.9172 - loss: 0.2458\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m390/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:16\u001b[0m 2s/step - accuracy: 0.9173 - loss: 0.2455\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m395/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:07\u001b[0m 2s/step - accuracy: 0.9174 - loss: 0.2453\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m400/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.9174 - loss: 0.2451 \n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m405/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9175 - loss: 0.2448\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m410/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.9176 - loss: 0.2446\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m415/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.9177 - loss: 0.2443\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m420/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.9177 - loss: 0.2441\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m425/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9178 - loss: 0.2438\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m430/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.9179 - loss: 0.2436\n",
      "Epoch 3: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch03.weights.h5\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9179 - loss: 0.2435\n",
      "Epoch 3: val_loss did not improve from 0.36257\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 2s/step - accuracy: 0.9180 - loss: 0.2434 - val_accuracy: 0.8148 - val_loss: 0.6539 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m  3/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:10\u001b[0m 2s/step - accuracy: 0.9311 - loss: 0.1924\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m  8/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:47\u001b[0m 15s/step - accuracy: 0.9263 - loss: 0.1965\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 13/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:24\u001b[0m 10s/step - accuracy: 0.9290 - loss: 0.1900\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 18/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49:54\u001b[0m 7s/step - accuracy: 0.9312 - loss: 0.1841\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 23/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40:56\u001b[0m 6s/step - accuracy: 0.9320 - loss: 0.1817\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 28/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35:15\u001b[0m 5s/step - accuracy: 0.9320 - loss: 0.1812\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 33/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:19\u001b[0m 5s/step - accuracy: 0.9318 - loss: 0.1823\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 38/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:21\u001b[0m 4s/step - accuracy: 0.9319 - loss: 0.1829\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 43/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26:03\u001b[0m 4s/step - accuracy: 0.9321 - loss: 0.1831\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 48/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24:14\u001b[0m 4s/step - accuracy: 0.9322 - loss: 0.1834\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 53/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22:46\u001b[0m 4s/step - accuracy: 0.9323 - loss: 0.1835\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 58/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:30\u001b[0m 3s/step - accuracy: 0.9324 - loss: 0.1839\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 63/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:25\u001b[0m 3s/step - accuracy: 0.9325 - loss: 0.1844\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 68/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:28\u001b[0m 3s/step - accuracy: 0.9325 - loss: 0.1849\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 73/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:38\u001b[0m 3s/step - accuracy: 0.9324 - loss: 0.1855\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 78/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:56\u001b[0m 3s/step - accuracy: 0.9324 - loss: 0.1859\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 83/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:17\u001b[0m 3s/step - accuracy: 0.9324 - loss: 0.1861\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 88/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:42\u001b[0m 3s/step - accuracy: 0.9325 - loss: 0.1863\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 93/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:09\u001b[0m 3s/step - accuracy: 0.9325 - loss: 0.1865\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m 98/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:39\u001b[0m 3s/step - accuracy: 0.9326 - loss: 0.1866\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m103/432\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:11\u001b[0m 3s/step - accuracy: 0.9326 - loss: 0.1867\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m108/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:45\u001b[0m 3s/step - accuracy: 0.9327 - loss: 0.1867\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m113/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:20\u001b[0m 3s/step - accuracy: 0.9328 - loss: 0.1869\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m118/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:56\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1870\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m123/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:34\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1871\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m128/432\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:12\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1872\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m133/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:52\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1874\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m138/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:33\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1876\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m143/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:14\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1879\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m148/432\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:55\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1881\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m153/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m11:37\u001b[0m 3s/step - accuracy: 0.9329 - loss: 0.1883\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m158/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m11:20\u001b[0m 2s/step - accuracy: 0.9328 - loss: 0.1885\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m163/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m11:03\u001b[0m 2s/step - accuracy: 0.9328 - loss: 0.1888\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m168/432\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10:47\u001b[0m 2s/step - accuracy: 0.9327 - loss: 0.1891\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m173/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m10:31\u001b[0m 2s/step - accuracy: 0.9327 - loss: 0.1896\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m178/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m33:07\u001b[0m 8s/step - accuracy: 0.9326 - loss: 0.1900\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m183/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m31:47\u001b[0m 8s/step - accuracy: 0.9325 - loss: 0.1904\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m188/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30:31\u001b[0m 8s/step - accuracy: 0.9324 - loss: 0.1908\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m193/432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29:18\u001b[0m 7s/step - accuracy: 0.9324 - loss: 0.1913\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m198/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m28:09\u001b[0m 7s/step - accuracy: 0.9323 - loss: 0.1918\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m203/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m27:03\u001b[0m 7s/step - accuracy: 0.9322 - loss: 0.1923\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m208/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26:00\u001b[0m 7s/step - accuracy: 0.9321 - loss: 0.1928\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m213/432\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24:58\u001b[0m 7s/step - accuracy: 0.9320 - loss: 0.1933\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m218/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23:59\u001b[0m 7s/step - accuracy: 0.9319 - loss: 0.1938\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m223/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23:02\u001b[0m 7s/step - accuracy: 0.9318 - loss: 0.1942\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m228/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m22:07\u001b[0m 7s/step - accuracy: 0.9317 - loss: 0.1946\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m233/432\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21:14\u001b[0m 6s/step - accuracy: 0.9317 - loss: 0.1950\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m238/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m20:24\u001b[0m 6s/step - accuracy: 0.9316 - loss: 0.1954\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m243/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m19:35\u001b[0m 6s/step - accuracy: 0.9315 - loss: 0.1958\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m248/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18:48\u001b[0m 6s/step - accuracy: 0.9315 - loss: 0.1962\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m253/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18:03\u001b[0m 6s/step - accuracy: 0.9314 - loss: 0.1966\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m258/432\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17:18\u001b[0m 6s/step - accuracy: 0.9313 - loss: 0.1970\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m263/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16:35\u001b[0m 6s/step - accuracy: 0.9313 - loss: 0.1973\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m268/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15:53\u001b[0m 6s/step - accuracy: 0.9312 - loss: 0.1976\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m273/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15:12\u001b[0m 6s/step - accuracy: 0.9311 - loss: 0.1980\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m278/432\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14:32\u001b[0m 6s/step - accuracy: 0.9311 - loss: 0.1983\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m283/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13:54\u001b[0m 6s/step - accuracy: 0.9310 - loss: 0.1987\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m288/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13:17\u001b[0m 6s/step - accuracy: 0.9310 - loss: 0.1990\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m293/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12:40\u001b[0m 5s/step - accuracy: 0.9309 - loss: 0.1992\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m298/432\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12:05\u001b[0m 5s/step - accuracy: 0.9309 - loss: 0.1995\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m303/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11:30\u001b[0m 5s/step - accuracy: 0.9308 - loss: 0.1998\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m308/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10:56\u001b[0m 5s/step - accuracy: 0.9308 - loss: 0.2000\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m313/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10:22\u001b[0m 5s/step - accuracy: 0.9307 - loss: 0.2002\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m318/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9:50\u001b[0m 5s/step - accuracy: 0.9307 - loss: 0.2004\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m323/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9:18\u001b[0m 5s/step - accuracy: 0.9307 - loss: 0.2006\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m328/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8:47\u001b[0m 5s/step - accuracy: 0.9306 - loss: 0.2008\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m333/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8:17\u001b[0m 5s/step - accuracy: 0.9306 - loss: 0.2010\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m338/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7:47\u001b[0m 5s/step - accuracy: 0.9306 - loss: 0.2011\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m343/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7:18\u001b[0m 5s/step - accuracy: 0.9306 - loss: 0.2013\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m348/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6:50\u001b[0m 5s/step - accuracy: 0.9305 - loss: 0.2014\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m353/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6:22\u001b[0m 5s/step - accuracy: 0.9305 - loss: 0.2016\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m358/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5:55\u001b[0m 5s/step - accuracy: 0.9305 - loss: 0.2017\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m363/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5:28\u001b[0m 5s/step - accuracy: 0.9305 - loss: 0.2018\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m368/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5:01\u001b[0m 5s/step - accuracy: 0.9304 - loss: 0.2019\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m373/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4:36\u001b[0m 5s/step - accuracy: 0.9304 - loss: 0.2020\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m378/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4:10\u001b[0m 5s/step - accuracy: 0.9304 - loss: 0.2022\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m383/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:45\u001b[0m 5s/step - accuracy: 0.9304 - loss: 0.2023\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m388/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:21\u001b[0m 5s/step - accuracy: 0.9304 - loss: 0.2024\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m393/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:56\u001b[0m 5s/step - accuracy: 0.9303 - loss: 0.2025\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m398/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:33\u001b[0m 5s/step - accuracy: 0.9303 - loss: 0.2026\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m403/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:09\u001b[0m 4s/step - accuracy: 0.9303 - loss: 0.2027\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m408/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:46\u001b[0m 4s/step - accuracy: 0.9303 - loss: 0.2028\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m413/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:23\u001b[0m 4s/step - accuracy: 0.9303 - loss: 0.2029\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m418/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:01\u001b[0m 4s/step - accuracy: 0.9302 - loss: 0.2029\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m423/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m39s\u001b[0m 4s/step - accuracy: 0.9302 - loss: 0.2030\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m428/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.9302 - loss: 0.2030\n",
      "Epoch 4: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch04.weights.h5\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9302 - loss: 0.2031\n",
      "Epoch 4: val_loss improved from 0.36257 to 0.33790, saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\best_trained_weights.weights.h5\n",
      "\u001b[1m432/432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1910s\u001b[0m 4s/step - accuracy: 0.9302 - loss: 0.2031 - val_accuracy: 0.8839 - val_loss: 0.3379 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m  1/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:38\u001b[0m 4s/step - accuracy: 0.9200 - loss: 0.1773\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m  6/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:46\u001b[0m 2s/step - accuracy: 0.9434 - loss: 0.1585\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 11/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:38\u001b[0m 2s/step - accuracy: 0.9470 - loss: 0.1664\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 16/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:57\u001b[0m 2s/step - accuracy: 0.9452 - loss: 0.1818\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 21/432\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:28\u001b[0m 2s/step - accuracy: 0.9434 - loss: 0.1898\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 26/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:19\u001b[0m 2s/step - accuracy: 0.9415 - loss: 0.1948\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 31/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:00\u001b[0m 2s/step - accuracy: 0.9404 - loss: 0.1979\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 36/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:38\u001b[0m 2s/step - accuracy: 0.9397 - loss: 0.1991\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 41/432\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:30\u001b[0m 2s/step - accuracy: 0.9391 - loss: 0.2002\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 46/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:17\u001b[0m 2s/step - accuracy: 0.9387 - loss: 0.2009\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 51/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:03\u001b[0m 2s/step - accuracy: 0.9384 - loss: 0.2014\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 56/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:48\u001b[0m 2s/step - accuracy: 0.9382 - loss: 0.2013\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 61/432\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:36\u001b[0m 2s/step - accuracy: 0.9381 - loss: 0.2010\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 66/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:25\u001b[0m 2s/step - accuracy: 0.9381 - loss: 0.2003\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n",
      "\u001b[1m 71/432\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:15\u001b[0m 2s/step - accuracy: 0.9381 - loss: 0.1995\n",
      "Epoch 5: saving model to C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] Can't write data (file write failed: time = Sat Aug 10 07:17:07 2024\n, filename = 'C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5', file descriptor = 3, errno = 28, error message = 'No space left on device', buf = 000002702DB7C040, total write size = 2359296, bytes this sub-write = 2359296, bytes actually written = 18446744073709551615, offset = 147676704)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 318\u001b[0m\n\u001b[0;32m    313\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m), \n\u001b[0;32m    314\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    315\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m#history = model.fit(train_dataset, validation_data=test_dataset, epochs=no_epochs)\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    319\u001b[0m     train_dataset,\n\u001b[0;32m    320\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mno_epochs,\n\u001b[0;32m    321\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[0;32m    322\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight_dict,\n\u001b[0;32m    323\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[reduce_lr, early_stopping, dynamic_checkpoint_callback, best_model_checkpoint_callback]\n\u001b[0;32m    324\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\group.py:483\u001b[0m, in \u001b[0;36mGroup.__setitem__\u001b[1;34m(self, name, obj)\u001b[0m\n\u001b[0;32m    480\u001b[0m     htype\u001b[38;5;241m.\u001b[39mcommit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, name, lcpl\u001b[38;5;241m=\u001b[39mlcpl)\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    484\u001b[0m     h5o\u001b[38;5;241m.\u001b[39mlink(ds\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, name, lcpl\u001b[38;5;241m=\u001b[39mlcpl)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\dataset.py:166\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m h5d\u001b[38;5;241m.\u001b[39mcreate(parent\u001b[38;5;241m.\u001b[39mid, name, tid, sid, dcpl\u001b[38;5;241m=\u001b[39mdcpl, dapl\u001b[38;5;241m=\u001b[39mdapl)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[1;32m--> 166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset_id\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5d.pyx:282\u001b[0m, in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_proxy.pyx:115\u001b[0m, in \u001b[0;36mh5py._proxy.dset_rw\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] Can't write data (file write failed: time = Sat Aug 10 07:17:07 2024\n, filename = 'C:\\Users\\abudh\\Desktop\\CropWatch\\Training_trained_model_epoch05.weights.h5', file descriptor = 3, errno = 28, error message = 'No space left on device', buf = 000002702DB7C040, total write size = 2359296, bytes this sub-write = 2359296, bytes actually written = 18446744073709551615, offset = 147676704)"
     ]
    }
   ],
   "source": [
    "# Essential and common packages\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Read and visualize the raster data\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Plots and bars\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Computation library\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow for building the resnet50 model\n",
    "import tensorflow.python.keras as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# Sklearn for confusion matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import itertools\n",
    "# For visualization of plots without plt.show()\n",
    "%matplotlib inline\n",
    "\n",
    "dataset_url =r'C:\\Users\\abudh\\Desktop\\CropWatch\\EuroSAT\\2750'\n",
    "batch_size = 50\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "validation_split=0.2\n",
    "rescale=1.0/255\n",
    "no_epochs = 20\n",
    "\n",
    "\n",
    "# 3. Data Augmentation and Loading\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=rescale,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=validation_split\n",
    ")\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_url, image_size=(img_height, img_width), batch_size=batch_size)\n",
    "\n",
    "train_dataset = datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(img_height, img_width),\n",
    "                                           subset=\"training\",\n",
    "                                           class_mode='categorical')\n",
    "\n",
    "\n",
    "test_dataset = datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(img_height, img_width),\n",
    "                                           subset=\"validation\",\n",
    "                                           class_mode='categorical')\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_indices = train_dataset.class_indices\n",
    "class_labels = list(class_indices.keys())\n",
    "class_indices = list(class_indices.values())\n",
    "\n",
    "class_counts_dict = {class_name: len(glob.glob(os.path.join(dataset_url, class_name, '*'))) for class_name in class_labels}\n",
    "class_counts = np.array([class_counts_dict[class_name] for class_name in class_labels])\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(class_indices),\n",
    "    y=np.array([train_dataset.classes[i] for i in range(len(train_dataset.classes))])\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(zip(class_labels, weights))\n",
    "print(\"Class weights:\")\n",
    "for label, weight in class_weight_dict.items():\n",
    "    print(f\"Class '{label}': {weight:.4f}\")\n",
    "\n",
    "\n",
    "class_names = dataset.class_names\n",
    "no_class= (len(class_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value.\n",
    "    X_shortcut = X\n",
    "    cache = []\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = X = Activation('relu')(X, training = training)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), padding = 'valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = len(class_names)):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "   # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size = (2, 2), name = 'avg_pool')(X)\n",
    "    \n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the path where the weights will be saved\n",
    "model_path = r'C:\\Users\\abudh\\Desktop\\CropWatch'\n",
    "\n",
    "# Define the checkpoint callback to save weights every 5 epochs with a dynamic name\n",
    "dynamic_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=model_path + r'\\Training_trained_model_epoch{epoch:02d}.weights.h5',  # Use .weights.h5 extension\n",
    "    save_freq=5,  # Save at the end of every epoch\n",
    "    save_weights_only=True,  # Save only weights\n",
    "    verbose=1  # Verbose mode to show saving information\n",
    ")\n",
    "\n",
    "# Define the checkpoint callback to save only the best weights based on validation loss\n",
    "best_model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=model_path + r'\\best_trained_weights.weights.h5',  # Use .weights.h5 extension\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    mode='min',  # Minimize the loss\n",
    "    save_best_only=True,  # Save only the best weights\n",
    "    save_weights_only=True,  # Save only weights\n",
    "    verbose=1  # Verbose mode to show saving information\n",
    ")\n",
    "\n",
    "\n",
    "model = ResNet50(input_shape=(img_height, img_width, 3), classes=len(class_labels))\n",
    "\n",
    "model.load_weights(r'C:\\Users\\abudh\\Desktop\\CropWatch\\best_weights.weights.h5')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#history = model.fit(train_dataset, validation_data=test_dataset, epochs=no_epochs)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=no_epochs,\n",
    "    validation_data=test_dataset,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[reduce_lr, early_stopping, dynamic_checkpoint_callback, best_model_checkpoint_callback]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87576c6-9ad7-45c9-81a7-e3645b822489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['val_accuracy'])\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_title('Accuracy over epoch')\n",
    "ax1.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_title('Loss over epoch')\n",
    "ax2.legend(['Train', 'Test'], loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for i, (image_batch, label_batch) in enumerate(test_dataset):   # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    preds = model.predict(image_batch)\n",
    "    # append predicted labels\n",
    "    y_pred.append(np.argmax(preds, axis =  1))\n",
    "    if i==300:\n",
    "        break\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "correct_labels = np.argmax(correct_labels, axis=1)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
    "cm = confusion_matrix(correct_labels, predicted_labels)\n",
    "cm\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2cbf73-8aaf-42ac-87c7-c7e0fec45ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117efe93-3c74-45b9-9864-7b45e41bed3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824a873-bfc6-4c2f-94bf-c99c35dc9923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
