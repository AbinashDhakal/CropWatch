{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81848637-e2b4-4073-8f21-a4b41dc14808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.initializers import glorot_uniform, random_uniform\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Configuration\n",
    "dataset_url = r'C:\\Users\\abudh\\Desktop\\CropWatch\\EuroSAT\\2750'\n",
    "test_folder = r'C:\\Users\\abudh\\Desktop\\CropWatch\\Test'\n",
    "filtered_image_folder = r'C:\\Users\\abudh\\Desktop\\CropWatch\\Filtered_Image'\n",
    "model_path = 'resnet50_model.h5'\n",
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "validation_split = 0.2\n",
    "rescale = 1.0 / 255\n",
    "epoch = 10\n",
    "n = 3  # Number of rows and columns to splice the image into\n",
    "vegetation_classes = [\"AnnualCrop\", \"Forest\", \"HerbaceousVegetation\", \"Pasture\", \"PermanentCrop\"]\n",
    "\n",
    "# Identity block for ResNet\n",
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = Conv2D(filters=F1, kernel_size=1, strides=(1, 1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "# Convolutional block for ResNet\n",
    "def convolutional_block(X, f, filters, s=2, training=True, initializer=glorot_uniform):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = Conv2D(filters=F1, kernel_size=1, strides=(s, s), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_initializer=initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3)(X_shortcut, training=training)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "# ResNet model definition\n",
    "def ResNet50(input_shape=(64, 64, 3), classes=6):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer='glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = AveragePooling2D(pool_size=(2, 2))(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer='glorot_uniform')(X)\n",
    "    model = tf.keras.models.Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    return model\n",
    "\n",
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.legend(['Train', 'Validation'], loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "# Prepare dataset\n",
    "def prepare_data(dataset_url, img_height, img_width, batch_size, validation_split, rescale):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_split, rescale=rescale)\n",
    "    train_dataset = datagen.flow_from_directory(directory=dataset_url, target_size=(img_height, img_width), batch_size=batch_size, subset=\"training\", class_mode='categorical')\n",
    "    test_dataset = datagen.flow_from_directory(directory=dataset_url, target_size=(img_height, img_width), batch_size=batch_size, subset=\"validation\", class_mode='categorical')\n",
    "    return train_dataset, test_dataset, list(train_dataset.class_indices.keys())\n",
    "\n",
    "# Train model\n",
    "def train_model(train_dataset, test_dataset, class_names, epochs=epoch):\n",
    "    model = ResNet50(input_shape=(img_height, img_width, 3), classes=len(class_names))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs)\n",
    "    model.save(model_path)\n",
    "    plot_training_history(history)\n",
    "    return model, history\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, test_dataset, class_names):\n",
    "    y_pred = []\n",
    "    y_true = test_dataset.classes\n",
    "    predictions = model.predict(test_dataset)\n",
    "    y_pred_classes = np.argmax(predictions, axis=1)\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    fmt = 'd'\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"black\")\n",
    "    plt.show()\n",
    "\n",
    "# Load images\n",
    "def load_images(directory):\n",
    "    image_files = glob.glob(os.path.join(directory, '*.*'))\n",
    "    images = []\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            with Image.open(file) as img:\n",
    "                img = img.resize((img_width, img_height))\n",
    "                img_array = np.array(img) / 255.0\n",
    "                if img_array.ndim == 3 and img_array.shape[2] == 3:\n",
    "                    images.append((file, img_array))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {file}: {e}\")\n",
    "    return images\n",
    "\n",
    "# Splice image\n",
    "def splice_image(file_path, n):\n",
    "    img = Image.open(file_path)\n",
    "    width, height = img.size\n",
    "    cropped_images = []\n",
    "    tile_width = width // n\n",
    "    tile_height = height // n\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            left = j * tile_width\n",
    "            upper = i * tile_height\n",
    "            right = left + tile_width\n",
    "            lower = upper + tile_height\n",
    "            cropped_img = img.crop((left, upper, right, lower))\n",
    "            cropped_images.append((cropped_img, i * n + j + 1))\n",
    "    return cropped_images\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess the input image by converting to grayscale and normalizing the contrast.\n",
    "    \n",
    "    Parameters:\n",
    "    image (PIL.Image.Image): The input image.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The preprocessed grayscale image.\n",
    "    \"\"\"\n",
    "    # Convert PIL image to OpenCV image format\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Normalize contrast\n",
    "    normalized_image = cv2.equalizeHist(gray_image)\n",
    "    return normalized_image\n",
    "\n",
    "def segment_clouds(image, threshold_value=200):\n",
    "    \"\"\"\n",
    "    Segment clouds in the preprocessed image using binary thresholding.\n",
    "    \n",
    "    Parameters:\n",
    "    image (np.ndarray): The preprocessed grayscale image.\n",
    "    threshold_value (int): The threshold value for binary segmentation (default: 200).\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The binary mask for the clouds.\n",
    "    \"\"\"\n",
    "    _, binary_mask = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    return binary_mask\n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    \"\"\"\n",
    "    Clean up the binary mask using morphological operations.\n",
    "    \n",
    "    Parameters:\n",
    "    mask (np.ndarray): The binary mask.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The cleaned binary mask.\n",
    "    \"\"\"\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    cleaned_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    cleaned_mask = cv2.morphologyEx(cleaned_mask, cv2.MORPH_OPEN, kernel)\n",
    "    return cleaned_mask\n",
    "\n",
    "def calculate_cloud_coverage(mask):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of the image covered by clouds.\n",
    "    \n",
    "    Parameters:\n",
    "    mask (np.ndarray): The cleaned binary mask.\n",
    "    \n",
    "    Returns:\n",
    "    float: The percentage of the image covered by clouds.\n",
    "    \"\"\"\n",
    "    total_pixels = mask.size\n",
    "    cloud_pixels = cv2.countNonZero(mask)\n",
    "    cloud_percentage = (cloud_pixels / total_pixels) * 100\n",
    "    return cloud_percentage\n",
    "\n",
    "\n",
    "\n",
    "def analyze_image_parts(image_path, n, threshold_percentage=30, threshold_value=200):\n",
    "    \"\"\"\n",
    "    Analyze the image parts for cloud coverage and store parts that meet the criteria.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): The path to the input image.\n",
    "    n (int): Number of rows and columns to splice the image into.\n",
    "    threshold_percentage (float): The threshold percentage for determining cloud coverage (default: 30).\n",
    "    threshold_value (int): The threshold value for binary segmentation (default: 200).\n",
    "    \"\"\"\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    output_folder = os.path.join(os.path.dirname(image_path), \"Filtered_Image\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    cropped_images = splice_image(image_path, n)\n",
    "    \n",
    "    for cropped_img, idx in cropped_images:\n",
    "        preprocessed_image = preprocess_image(cropped_img)\n",
    "        binary_mask = segment_clouds(preprocessed_image, threshold_value)\n",
    "        cleaned_mask = postprocess_mask(binary_mask)\n",
    "        cloud_percentage = calculate_cloud_coverage(cleaned_mask)\n",
    "        \n",
    "        status = \"Accepted\" if cloud_percentage < threshold_percentage else \"Rejected\"\n",
    "        print(f\"Part {idx} Cloud Coverage: {cloud_percentage:.2f}% - {status}\")\n",
    "        \n",
    "        if cloud_percentage < threshold_percentage:  # Save only if cloud coverage is below the threshold\n",
    "            output_name = f\"{base_name}_Q{idx}.png\"\n",
    "            output_path = os.path.join(output_folder, output_name)\n",
    "            cropped_img.save(output_path)\n",
    "\n",
    "\n",
    "# Classify and save images\n",
    "\n",
    "def classify_and_save_images(images, model, class_names, vegetation_classes, filtered_image_folder, n):\n",
    "    if not os.path.exists(filtered_image_folder):\n",
    "        os.makedirs(filtered_image_folder)\n",
    "\n",
    "    for veg_class in vegetation_classes:\n",
    "        class_folder = os.path.join(filtered_image_folder, veg_class)\n",
    "        if not os.path.exists(class_folder):\n",
    "            os.makedirs(class_folder)\n",
    "\n",
    "    for file_path, img_array in images:\n",
    "        try:\n",
    "            img_array_exp = np.expand_dims(img_array, axis=0)\n",
    "            prediction = model.predict(img_array_exp)\n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "            predicted_label = class_names[predicted_class]\n",
    "\n",
    "            if predicted_label in vegetation_classes:\n",
    "                # Splice the image if it's a vegetation class\n",
    "                cropped_images = splice_image(file_path, n)\n",
    "                \n",
    "                for cropped_img, idx in cropped_images:\n",
    "                    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "                    new_filename = f\"{base_name}_part{idx}.jpg\"\n",
    "                    save_path = os.path.join(filtered_image_folder, predicted_label, new_filename)\n",
    "\n",
    "                    cropped_img.save(save_path)\n",
    "                    print(f\"Spliced image {file_path} classified as {predicted_label} and saved to {save_path}\")\n",
    "            else:\n",
    "                print(f\"Image {file_path} classified as {predicted_label} but not a vegetation class.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {file_path}: {e}\")\n",
    "\n",
    "def display_images(image_folder):\n",
    "    \"\"\"\n",
    "    Display images from the specified folder.\n",
    "    \n",
    "    Parameters:\n",
    "    image_folder (str): The path to the folder containing images.\n",
    "    \"\"\"\n",
    "    images = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    num_images = len(images)\n",
    "    \n",
    "    if num_images == 0:\n",
    "        print(\"No images found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(os.path.basename(img_path))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def process_and_analyze_images(test_folder, n):\n",
    "    \"\"\"\n",
    "    Process and analyze all images in the test folder.\n",
    "    \n",
    "    Parameters:\n",
    "    test_folder (str): The path to the test folder containing images.\n",
    "    n (int): Number of rows and columns to splice the images into.\n",
    "    \"\"\"\n",
    "    for image_name in os.listdir(test_folder):\n",
    "        if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(test_folder, image_name)\n",
    "            analyze_image_parts(image_path, n)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load trained model\n",
    "def load_trained_model(model_path='resnet50_model.h5'):\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005ecd5c-f18f-4a83-8168-dd419643e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import openeo\n",
    "\n",
    "def load_data_from_openeo():\n",
    "    # Connect to the OpenEO back-end\n",
    "    connection = openeo.connect(\"https://openeo.dataspace.copernicus.eu\")\n",
    "\n",
    "    # Authenticate with the back-end\n",
    "    connection.authenticate_oidc()\n",
    "\n",
    "    # Load Sentinel-2 data collection\n",
    "    s2_cube = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n",
    "        spatial_extent={\n",
    "            \"west\": 3.20,\n",
    "            \"south\": 51.18,\n",
    "            \"east\": 3.25,\n",
    "            \"north\": 51.21,\n",
    "            \"crs\": \"EPSG:4326\",\n",
    "        },\n",
    "        bands=[\"B08\", \"B07\", \"B06\", \"B05\", \"B04\", \"B03\", \"B02\"],\n",
    "        max_cloud_cover=50,\n",
    "    )\n",
    "    \n",
    "    # Compute the median for the temporal extent\n",
    "    s2_median = s2_cube.reduce_dimension(dimension=\"t\", reducer=\"median\")\n",
    "    \n",
    "    # Download the results as an xarray dataset\n",
    "    job = s2_median.execute_batch(\"output.nc\", out_format=\"netCDF\")\n",
    "    job.download_results(\".\")\n",
    "\n",
    "    ds = xr.open_dataset(\"output.nc\")\n",
    "    return ds\n",
    "\n",
    "def load_data_from_directory(data_folder_path):\n",
    "    pattern = \"*.tiff\"\n",
    "    search_pattern = f\"{data_folder_path}\\\\{pattern}\"\n",
    "\n",
    "    # Use glob to find files matching the pattern\n",
    "    S_sentinel_bands = glob.glob(search_pattern)\n",
    "    print(\"Files found:\", S_sentinel_bands)\n",
    "\n",
    "    if S_sentinel_bands:\n",
    "        # Initialize a list to store band data and band names\n",
    "        band_data = []\n",
    "        band_names = []\n",
    "\n",
    "        # Read each TIFF file and append the first band to the list\n",
    "        for file_path in S_sentinel_bands:\n",
    "            try:\n",
    "                with rasterio.open(file_path) as ds:\n",
    "                    band_data.append(ds.read(1))\n",
    "                    band_names.append(ds.descriptions[0])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "        # Stack all bands into a single array\n",
    "        arr_st = np.stack(band_data)\n",
    "        print(\"Shape of stacked bands:\", arr_st.shape)\n",
    "\n",
    "        # Create an xarray dataset\n",
    "        ds = xr.Dataset({f\"B{str(i+1).zfill(2)}\": ([\"y\", \"x\"], arr_st[i]) for i in range(len(arr_st))})\n",
    "        return ds\n",
    "    else:\n",
    "        print(\"No files found.\")\n",
    "        return None\n",
    "\n",
    "# Functions to calculate various indices\n",
    "def calculate_evi(ds):\n",
    "    nir = ds[\"B08\"] * 0.0001\n",
    "    red = ds[\"B04\"] * 0.0001\n",
    "    blue = ds[\"B02\"] * 0.0001\n",
    "    evi = 2.5 * ((nir - red) / (nir + 6 * red - 7.5 * blue + 1))\n",
    "    return evi\n",
    "\n",
    "def calculate_lai(ds):\n",
    "    evi = calculate_evi(ds)\n",
    "    lai = (3.618 * evi - 0.118)\n",
    "    return lai\n",
    "\n",
    "def calculate_rvi(ds):\n",
    "    nir = ds[\"B08\"] * 0.0001\n",
    "    red = ds[\"B04\"] * 0.0001\n",
    "    rvi = nir / red\n",
    "    return rvi\n",
    "\n",
    "def calculate_pssra(ds):\n",
    "    nir = ds[\"B07\"] * 0.0001\n",
    "    red = ds[\"B04\"] * 0.0001\n",
    "    pssra = nir / red\n",
    "    return pssra\n",
    "\n",
    "def calculate_ndvi(ds):\n",
    "    nir = ds[\"B08\"] * 0.0001\n",
    "    red = ds[\"B04\"] * 0.0001\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    return ndvi\n",
    "\n",
    "def calculate_ndi45(ds):\n",
    "    nir = ds[\"B05\"] * 0.0001\n",
    "    red = ds[\"B04\"] * 0.0001\n",
    "    ndi45 = (nir - red) / (nir + red)\n",
    "    return ndi45\n",
    "\n",
    "def calculate_gndvi(ds):\n",
    "    nir = ds[\"B08\"] * 0.0001\n",
    "    green = ds[\"B03\"] * 0.0001\n",
    "    gndvi = (nir - green) / (nir + green)\n",
    "    return gndvi\n",
    "\n",
    "def calculate_mcari(ds):\n",
    "    red2 = ds[\"B05\"] * 0.0001\n",
    "    red1 = ds[\"B04\"] * 0.0001\n",
    "    green = ds[\"B03\"] * 0.0001\n",
    "    mcari = ((red2 - red1) - 0.2 * (red2 - green)) * (red2 / red1)\n",
    "    return mcari\n",
    "\n",
    "def calculate_s2rep(ds):\n",
    "    red1 = ds[\"B04\"] * 0.0001\n",
    "    nir = ds[\"B07\"] * 0.0001\n",
    "    red2 = ds[\"B05\"] * 0.0001\n",
    "    red3 = ds[\"B06\"] * 0.0001\n",
    "    s2rep = 705 + 35 * ((red1 + nir) / 2 - red2) / (red3 - red2)\n",
    "    return s2rep\n",
    "\n",
    "def calculate_ireci(ds):\n",
    "    nir = ds[\"B07\"] * 0.0001\n",
    "    red1 = ds[\"B04\"] * 0.0001\n",
    "    red2 = ds[\"B05\"] * 0.0001\n",
    "    red3 = ds[\"B06\"] * 0.0001\n",
    "    ireci = (nir - red1) / (red2 / red3)\n",
    "    return ireci\n",
    "\n",
    "def calculate_savi(ds, L=0.428):\n",
    "    nir = ds[\"B08\"] * 0.0001\n",
    "    red = ds[\"B04\"] * 0.0001\n",
    "    savi = (1 + L) * (nir - red) / (nir + red + L)\n",
    "    return savi\n",
    "\n",
    "def calculate_indices(ds):\n",
    "    indices = {\n",
    "        \"NDVI\": calculate_ndvi(ds),\n",
    "        \"SAVI\": calculate_savi(ds),\n",
    "        \"RVI\": calculate_rvi(ds),\n",
    "        \"PSSRa\": calculate_pssra(ds),\n",
    "        \"NDI45\": calculate_ndi45(ds),\n",
    "        \"GNDVI\": calculate_gndvi(ds),\n",
    "        \"MCARI\": calculate_mcari(ds),\n",
    "        \"S2REP\": calculate_s2rep(ds),\n",
    "        \"IRECI\": calculate_ireci(ds),\n",
    "        \"LAI\": calculate_lai(ds),\n",
    "        \"EVI\": calculate_evi(ds),\n",
    "    }\n",
    "    return indices\n",
    "\n",
    "def plot_images(ds, index, title):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6), dpi=90)\n",
    "\n",
    "    red = ds[\"B04\"] * 0.0001\n",
    "    green = ds[\"B03\"] * 0.0001\n",
    "    blue = ds[\"B02\"] * 0.0001\n",
    "    rgb = np.stack([red, green, blue], axis=-1)\n",
    "    rgb = np.clip(rgb / np.percentile(rgb, 99.5), 0, 1)\n",
    "\n",
    "    axes[0].imshow(rgb)\n",
    "    axes[0].set_title(\"RGB Composite\")\n",
    "    axes[0].set_xlabel(\"Pixel X\")\n",
    "    axes[0].set_ylabel(\"Pixel Y\")\n",
    "\n",
    "    cax2 = axes[1].imshow(index, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "    axes[1].set_title(title)\n",
    "    axes[1].set_xlabel(\"Pixel X\")\n",
    "    axes[1].set_ylabel(\"Pixel Y\")\n",
    "    \n",
    "    cbar2 = plt.colorbar(cax2, ax=axes[1], orientation='vertical')\n",
    "    cbar2.set_label(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def select_data_source():\n",
    "    choice = input(\"Choose data source (1: OpenEO, 2: Local Directory): \").strip()\n",
    "\n",
    "    if choice == '1':\n",
    "        ds = load_data_from_openeo()\n",
    "        print(\"Data loaded from OpenEO.\")\n",
    "    elif choice == '2':\n",
    "        # Provide a hint for the directory path using a raw string\n",
    "        default_path = r\"C:\\Users\\abudh\\Desktop\\CropWatch\\SunderabanData\"\n",
    "        print(f\"Hint: The path to the data folder (e.g., {default_path})\")\n",
    "        \n",
    "        # Prompt the user for the path, using the default path if none is provided\n",
    "        data_folder_path = input(f\"Enter the path to the data folder [{default_path}]: \").strip()\n",
    "        if not data_folder_path:\n",
    "            data_folder_path = default_path\n",
    "        \n",
    "        # Load data from the local directory\n",
    "        ds = load_data_from_directory(data_folder_path)\n",
    "        if ds is None:\n",
    "            print(\"No data found or could not load data from the directory.\")\n",
    "            return\n",
    "        \n",
    "        print(\"Data loaded from local directory.\")\n",
    "    else:\n",
    "        print(\"Invalid choice. Please select 1 or 2.\")\n",
    "        return\n",
    "\n",
    "    # Calculate indices\n",
    "    indices = calculate_indices(ds)\n",
    "    \n",
    "    # Plot results\n",
    "    for index_name, index_data in indices.items():\n",
    "        plot_images(ds, index_data, index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7e2ba-6147-47f4-afc7-01afa4199342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21600 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abudh\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1122s\u001b[0m 1s/step - accuracy: 0.4607 - loss: 1.8914 - val_accuracy: 0.1980 - val_loss: 12.6360\n",
      "Epoch 2/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3216s\u001b[0m 5s/step - accuracy: 0.6753 - loss: 1.0207 - val_accuracy: 0.4565 - val_loss: 1.7815\n",
      "Epoch 3/10\n",
      "\u001b[1m138/675\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:59\u001b[0m 1s/step - accuracy: 0.7403 - loss: 0.7700"
     ]
    }
   ],
   "source": [
    "# Execute the workflow\n",
    "train_dataset, test_dataset, class_names = prepare_data(dataset_url, img_height, img_width, batch_size, validation_split, rescale)\n",
    "model, history = train_model(train_dataset, test_dataset, class_names, epochs=epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf8229-a6b5-4cf1-b666-b65f11790f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_dataset, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e06994-1dff-4126-aba4-c66e0f10eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(filtered_image_folder)\n",
    "classify_and_save_images(images, model, class_names, vegetation_classes, filtered_image_folder, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd20f4-afb3-4d53-b81e-faf7ee55e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze and display images\n",
    "process_and_analyze_images(test_folder, n)\n",
    "display_images(filtered_image_folder)\n",
    "\n",
    "#Running Trained Model\n",
    "# Main execution\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "#Classification of data\n",
    "\n",
    "print(\"Loading and processing images...\")\n",
    "images = load_images(test_folder)\n",
    "if images:\n",
    "    classify_and_save_images(images, model, class_names, vegetation_classes, filtered_image_folder, n)\n",
    "else:\n",
    "    print(\"No images found or loading error.\")\n",
    "print(\"Image processing complete.\")\n",
    "\n",
    "\n",
    "\n",
    "# Directly call the select_data_source function; Local Disk or Copernicus API with desired location\n",
    "select_data_source()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9cd41-abfc-4c1f-9963-a8e439c35451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb694f-eff8-442a-9f47-2613ffb9d5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c47a8-383e-43ad-a3cf-02f4bfe980a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
