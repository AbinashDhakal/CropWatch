{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef8bd59-5bb1-4fb1-a65f-553ab73a8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, \n",
    "                                     AveragePooling2D, MaxPooling2D)\n",
    "from tensorflow.keras.initializers import glorot_uniform, random_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Configuration\n",
    "dataset_url = r'C:\\Users\\abudh\\Desktop\\CropWatch\\EuroSAT\\2750'\n",
    "model_path = r'C:\\Users\\abudh\\Desktop\\CropWatch\\Training_model.h5'\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "validation_split = 0.2\n",
    "rescale = 1.0 / 255\n",
    "epochs = 1  # Adjust the number of epochs as needed\n",
    "\n",
    "# Identity block for ResNet\n",
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = Conv2D(filters=F1, kernel_size=1, strides=(1, 1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "# Convolutional block for ResNet\n",
    "def convolutional_block(X, f, filters, s=2, training=True, initializer=glorot_uniform):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = Conv2D(filters=F1, kernel_size=1, strides=(s, s), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training=training)\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_initializer=initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3)(X_shortcut, training=training)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "# ResNet model definition\n",
    "def ResNet50(input_shape=(64, 64, 3), classes=10):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = AveragePooling2D(pool_size=(2, 2))(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    return model\n",
    "\n",
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "# Prepare dataset\n",
    "def prepare_data(dataset_url, img_height, img_width, batch_size, validation_split, rescale):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_split, rescale=rescale)\n",
    "    train_dataset = datagen.flow_from_directory(directory=dataset_url, target_size=(img_height, img_width), \n",
    "                                                batch_size=batch_size, subset=\"training\", class_mode='categorical')\n",
    "    test_dataset = datagen.flow_from_directory(directory=dataset_url, target_size=(img_height, img_width), \n",
    "                                               batch_size=batch_size, subset=\"validation\", class_mode='categorical')\n",
    "    return train_dataset, test_dataset, list(train_dataset.class_indices.keys())\n",
    "\n",
    "# Train model\n",
    "def train_model(train_dataset, test_dataset, class_names, epochs=epochs):\n",
    "    model = ResNet50(input_shape=(img_height, img_width, 3), classes=len(class_names))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs)\n",
    "    model.save(model_path)\n",
    "    plot_training_history(history)\n",
    "    return model, history\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, test_dataset, class_names):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    # Iterate over the test dataset\n",
    "    for images, labels in test_dataset:\n",
    "        y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "        predictions = model.predict(images)\n",
    "        y_pred.extend(np.argmax(predictions, axis=1))\n",
    "        \n",
    "        if len(y_true) >= test_dataset.samples:\n",
    "            break\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, figsize=(10, 7)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    fmt = 'd'\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"black\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f22168-4396-4583-8806-7ac3dfc568be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21600 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main execution\n",
    "train_dataset, test_dataset, class_names = prepare_data(dataset_url, img_height, img_width, batch_size, validation_split, rescale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc2912-a3ed-4d3a-962d-eb6881c9de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abudh\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 1s/step - accuracy: 0.4517 - loss: 1.9825 - val_accuracy: 0.4456 - val_loss: 1.7194\n",
      "Epoch 2/2\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6339 - loss: 1.1282"
     ]
    }
   ],
   "source": [
    "\n",
    "model, history = train_model(train_dataset, test_dataset, class_names)\n",
    "evaluate_model(model, test_dataset, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cae73e-9c89-42bb-a2ad-6594fbb0af87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4888476-1a89-4706-a552-f988a52985e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
